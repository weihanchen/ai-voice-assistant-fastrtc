# Quickstart: Realtime Conversation UI

**Feature**: 005-realtime-conversation-ui
**Date**: 2025-12-31

## æ¦‚è¿°

æœ¬æŒ‡å—èªªæ˜å¦‚ä½•åœ¨ç¾æœ‰èªéŸ³åŠ©ç†ä¸­å•Ÿç”¨å³æ™‚å°è©±é¡¯ç¤ºåŠŸèƒ½ã€‚

---

## å‰ç½®éœ€æ±‚

- å·²å®Œæˆ 001-fastrtc-voice-pipeline è¨­å®š
- Python 3.13+ ç’°å¢ƒ
- FastRTC >=0.0.33

---

## å¿«é€Ÿæ•´åˆ

### 1. æ›´æ–° schemas.py

æ–°å¢å°è©±è¨Šæ¯å’Œæ­·å²æ¨¡å‹ï¼š

```python
# src/voice_assistant/voice/schemas.py

class ConversationMessage(BaseModel):
    """å–®ä¸€å°è©±è¨Šæ¯"""
    role: Literal["user", "assistant"]
    content: str
    timestamp: datetime = Field(default_factory=datetime.now)


class ConversationHistory(BaseModel):
    """å°è©±æ­·å²"""
    messages: list[ConversationMessage] = Field(default_factory=list)
    max_messages: int = 40

    def add_user_message(self, content: str) -> None:
        self._add_message("user", content)

    def add_assistant_message(self, content: str) -> None:
        self._add_message("assistant", content)

    def _add_message(self, role: str, content: str) -> None:
        self.messages.append(ConversationMessage(role=role, content=content))
        if len(self.messages) > self.max_messages:
            self.messages = self.messages[-self.max_messages:]

    def to_gradio_format(self) -> list[dict]:
        return [{"role": m.role, "content": m.content} for m in self.messages]
```

### 2. å»ºç«‹ UI æ¨¡çµ„

```python
# src/voice_assistant/voice/ui/blocks.py

import gradio as gr
from gradio_webrtc import WebRTC

def create_conversation_ui() -> tuple[gr.Blocks, gr.Textbox, gr.Chatbot, WebRTC]:
    """å»ºç«‹å°è©± UI"""
    with gr.Blocks(title="AI èªéŸ³åŠ©ç†") as blocks:
        gr.Markdown("# ğŸ¤ AI èªéŸ³åŠ©ç†")

        status = gr.Textbox(
            label="ç‹€æ…‹",
            value="ğŸŸ¢ å¾…å‘½",
            interactive=False,
        )

        chatbot = gr.Chatbot(
            label="å°è©±è¨˜éŒ„",
            type="messages",
            height=400,
        )

        audio = WebRTC(
            mode="send-receive",
            modality="audio",
            label="èªéŸ³è¼¸å…¥/è¼¸å‡º",
        )

    return blocks, status, chatbot, audio
```

### 3. ä¿®æ”¹ pipeline.py

åœ¨ `process_audio` ä¸­ yield AdditionalOutputsï¼š

```python
from fastrtc import AdditionalOutputs

def process_audio_with_outputs(self, audio):
    # ... STT è™•ç† ...
    user_text = self.stt.stt(audio)
    self.state.history.add_user_message(user_text)

    # ç™¼é€ UI æ›´æ–°
    yield AdditionalOutputs(
        self.state.history.to_gradio_format(),
        "â³ è™•ç†ä¸­..."
    )

    # ... LLM è™•ç† ...
    response = self._call_llm(user_text)
    self.state.history.add_assistant_message(response)

    yield AdditionalOutputs(
        self.state.history.to_gradio_format(),
        "ğŸ”Š å›æ‡‰ä¸­..."
    )

    # ... TTS ä¸²æµ ...
    for chunk in self.tts.stream(response):
        yield chunk

    yield AdditionalOutputs(
        self.state.history.to_gradio_format(),
        "ğŸŸ¢ å¾…å‘½"
    )
```

### 4. æ•´åˆ Stream èˆ‡ UI

```python
# src/voice_assistant/voice/handlers/reply_on_pause.py

from voice_assistant.voice.ui.blocks import create_conversation_ui

def create_voice_stream_with_ui(settings: Settings) -> Stream:
    # ... ç¾æœ‰è¨­å®š ...

    # å»ºç«‹è‡ªå®šç¾© UI
    blocks, status, chatbot, audio = create_conversation_ui()

    # è¨­å®šä¸²æµäº‹ä»¶
    audio.stream(
        fn=ReplyOnPause(pipeline.process_audio_with_outputs, ...),
        inputs=[audio],
        outputs=[audio],
    )

    # è¨­å®šé¡å¤–è¼¸å‡ºæ›´æ–°
    audio.on_additional_outputs(
        fn=lambda history, status_text: (history, status_text),
        outputs=[chatbot, status],
        queue=False,
    )

    # å»ºç«‹ Stream ä¸¦è¨­å®š UI
    stream = Stream(handler=..., modality="audio", mode="send-receive")
    stream.ui = blocks

    return stream
```

---

## ä½¿ç”¨æ–¹å¼

1. å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼ï¼š
   ```bash
   uv run python -m voice_assistant.main
   ```

2. é–‹å•Ÿç€è¦½å™¨è¨ªå• `http://localhost:7860`

3. å°è©±åŠŸèƒ½ï¼š
   - é»æ“Šéº¥å…‹é¢¨é–‹å§‹éŒ„éŸ³
   - èªªè©±å¾Œåœé “ 0.5 ç§’è§¸ç™¼è™•ç†
   - è§€å¯Ÿç‹€æ…‹å¾ã€Œå¾…å‘½ã€â†’ã€Œè†è½ã€â†’ã€Œè™•ç†ã€â†’ã€Œå›æ‡‰ã€
   - å°è©±è¨˜éŒ„å³æ™‚é¡¯ç¤ºæ–¼èŠå¤©å€

---

## é©—è­‰

### åŠŸèƒ½æª¢æŸ¥æ¸…å–®

- [ ] ç‹€æ…‹æŒ‡ç¤ºå™¨æ­£ç¢ºé¡¯ç¤ºç•¶å‰ç‹€æ…‹
- [ ] ä½¿ç”¨è€…èªéŸ³è¾¨è­˜çµæœå³æ™‚é¡¯ç¤º
- [ ] AI å›æ‡‰æ–‡å­—åŒæ­¥é¡¯ç¤º
- [ ] å°è©±æ­·å²å¯æ²å‹•ç€è¦½
- [ ] å¤šè¼ªå°è©±æ­£ç¢ºä¿ç•™

### æ•ˆèƒ½æª¢æŸ¥

- [ ] ASR æ–‡å­—é¡¯ç¤ºå»¶é² < 1 ç§’
- [ ] ç‹€æ…‹æ›´æ–°å»¶é² < 0.3 ç§’
- [ ] èªéŸ³æ’­æ”¾æµæš¢ç„¡å¡é “

---

## ç–‘é›£æ’è§£

### å•é¡Œï¼šå°è©±è¨˜éŒ„ä¸æ›´æ–°

**åŸå› **ï¼š`on_additional_outputs` æœªæ­£ç¢ºç¶å®š

**è§£æ±º**ï¼šç¢ºèª `queue=False` è¨­å®šæ­£ç¢º

### å•é¡Œï¼šç‹€æ…‹å¡åœ¨ã€Œè™•ç†ä¸­ã€

**åŸå› **ï¼šLLM æˆ– TTS è™•ç†ç•°å¸¸

**è§£æ±º**ï¼šæª¢æŸ¥å¾Œå° log ç¢ºèªéŒ¯èª¤è¨Šæ¯

### å•é¡Œï¼šéŸ³è¨Šæ­£å¸¸ä½†ç„¡æ–‡å­—

**åŸå› **ï¼š`AdditionalOutputs` æœªæ­£ç¢º yield

**è§£æ±º**ï¼šç¢ºèª `process_audio_with_outputs` æ­£ç¢ºå¯¦ä½œ
