"""Gradio Blocks UI å®šç¾©

æä¾›è‡ªå®šç¾©å°è©±ä»‹é¢ï¼Œæ•´åˆ WebRTC éŸ³è¨Šèˆ‡æ–‡å­—é¡¯ç¤ºã€‚
"""

import logging
from typing import TYPE_CHECKING

import gradio as gr
import numpy as np

if TYPE_CHECKING:
    from numpy.typing import NDArray

logger = logging.getLogger(__name__)


def create_additional_outputs() -> list[gr.components.Component]:
    """å»ºç«‹é¡å¤–è¼¸å‡ºå…ƒä»¶

    Returns:
        ç”¨æ–¼ Stream additional_outputs çš„å…ƒä»¶åˆ—è¡¨ï¼š
        [chatbot, status_display]
    """
    chatbot = gr.Chatbot(
        label="å°è©±è¨˜éŒ„",
        type="messages",
        height=400,
        show_label=True,
    )

    status_display = gr.Textbox(
        label="ç‹€æ…‹",
        value="ğŸŸ¢ å¾…å‘½",
        interactive=False,
        show_label=True,
    )

    return [chatbot, status_display]


def additional_outputs_handler(
    old_chatbot: list[dict[str, str]],
    old_status: str,
    new_history: list[dict[str, str]],
    new_status: str,
) -> tuple[list[dict[str, str]], str]:
    """è™•ç† AdditionalOutputs çš„å›å‘¼

    FastRTC çš„ additional_outputs_handler ç°½ç« ç‚ºï¼š
    (old_1, old_2, ..., new_1, new_2, ...) -> (result_1, result_2, ...)

    å…¶ä¸­ old_* æ˜¯ç›®å‰ UI å…ƒä»¶çš„ç‹€æ…‹ï¼Œnew_* æ˜¯ä¾†è‡ª AdditionalOutputs çš„æ–°è³‡æ–™ã€‚

    Args:
        old_chatbot: ç›®å‰ Chatbot ç‹€æ…‹ï¼ˆç”± Gradio è‡ªå‹•å‚³å…¥ï¼‰
        old_status: ç›®å‰ç‹€æ…‹é¡¯ç¤ºç‹€æ…‹ï¼ˆç”± Gradio è‡ªå‹•å‚³å…¥ï¼‰
        new_history: ä¾†è‡ª AdditionalOutputs çš„å°è©±æ­·å²
        new_status: ä¾†è‡ª AdditionalOutputs çš„ç‹€æ…‹æ–‡å­—

    Returns:
        (updated_chatbot, updated_status)
    """
    try:
        logger.debug(f"[UI] æ›´æ–° - ç‹€æ…‹: {new_status}, è¨Šæ¯æ•¸: {len(new_history)}")
        return (new_history, new_status)
    except Exception as e:
        logger.error(f"[UI] æ›´æ–°å¤±æ•—: {e}", exc_info=True)
        return (old_chatbot, old_status)


def create_audio_input() -> gr.Audio:
    """å»ºç«‹éŸ³è¨Šä¸Šå‚³å…ƒä»¶

    ç”¨æ–¼ä¸Šå‚³é éŒ„éŸ³è¨Šæª”æ¡ˆï¼Œæ›¿ä»£éº¥å…‹é¢¨è¼¸å…¥é€²è¡Œæ¸¬è©¦ã€‚

    Returns:
        gr.Audio: éŸ³è¨Šä¸Šå‚³å…ƒä»¶
    """
    return gr.Audio(
        label="ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆï¼ˆæ¸¬è©¦ç”¨ï¼‰",
        type="numpy",
        sources=["upload"],
        show_label=True,
    )


def audio_input_handler(
    audio: tuple[int, "NDArray[np.float32]"] | None,
) -> tuple[int, "NDArray[np.float32]"] | None:
    """è™•ç†ä¸Šå‚³çš„éŸ³è¨Šæª”æ¡ˆ

    å°‡ä¸Šå‚³çš„éŸ³è¨Šè½‰æ›ç‚º FastRTC æœŸæœ›çš„æ ¼å¼ã€‚

    Args:
        audio: (sample_rate, audio_array) æˆ– None

    Returns:
        è½‰æ›å¾Œçš„éŸ³è¨Š tuple æˆ– None
    """
    if audio is None:
        logger.debug("[UI] ç„¡éŸ³è¨Šè¼¸å…¥")
        return None

    sample_rate, audio_array = audio
    logger.info(
        f"[UI] æ”¶åˆ°ä¸Šå‚³éŸ³è¨Š: sample_rate={sample_rate}, "
        f"shape={audio_array.shape}, dtype={audio_array.dtype}"
    )

    # ç¢ºä¿éŸ³è¨Šç‚º float32 æ ¼å¼
    if audio_array.dtype != np.float32:
        if audio_array.dtype == np.int16:
            audio_array = audio_array.astype(np.float32) / 32768.0
        elif audio_array.dtype == np.int32:
            audio_array = audio_array.astype(np.float32) / 2147483648.0
        else:
            audio_array = audio_array.astype(np.float32)
        logger.debug(f"[UI] éŸ³è¨Šè½‰æ›ç‚º float32: dtype={audio_array.dtype}")

    # ç¢ºä¿éŸ³è¨Šç‚ºå–®è²é“
    if audio_array.ndim > 1:
        audio_array = audio_array.mean(axis=1)
        logger.debug(f"[UI] éŸ³è¨Šè½‰æ›ç‚ºå–®è²é“: shape={audio_array.shape}")

    return (sample_rate, audio_array)


def create_custom_ui(
    webrtc_component: gr.components.Component,
    chatbot: gr.Chatbot,
    status_display: gr.Textbox,
    process_uploaded_audio_fn: callable,
) -> gr.Blocks:
    """å»ºç«‹åŒ…å«éŸ³è¨Šä¸Šå‚³åŠŸèƒ½çš„è‡ªè¨‚ UI

    Args:
        webrtc_component: FastRTC WebRTC å…ƒä»¶
        chatbot: å°è©±è¨˜éŒ„å…ƒä»¶
        status_display: ç‹€æ…‹é¡¯ç¤ºå…ƒä»¶
        process_uploaded_audio_fn: è™•ç†ä¸Šå‚³éŸ³è¨Šçš„å›å‘¼å‡½å¼

    Returns:
        gr.Blocks: è‡ªè¨‚çš„ Gradio Blocks UI
    """
    column_css = (
        ".my-column {"
        "display: flex !important; "
        "justify-content: center !important; "
        "align-items: center !important"
        "};"
    )
    with gr.Blocks(title="AI èªéŸ³åŠ©ç†", css=column_css) as demo:
        gr.HTML("<h1 style='text-align: center'>AI èªéŸ³åŠ©ç†</h1>")

        with gr.Row():
            # å·¦å´ï¼šWebRTC ä¸²æµ
            with gr.Column(scale=1):
                webrtc_component.render()

                # éŸ³è¨Šä¸Šå‚³å€
                with gr.Accordion("ğŸ“ éŸ³è¨Šæª”æ¡ˆæ¸¬è©¦", open=False):
                    audio_input = gr.Audio(
                        label="ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ",
                        type="numpy",
                        sources=["upload"],
                    )
                    submit_btn = gr.Button("ğŸ¯ è™•ç†éŸ³è¨Š", variant="primary")

            # å³å´ï¼šå°è©±è¨˜éŒ„èˆ‡ç‹€æ…‹
            with gr.Column(scale=1):
                chatbot.render()
                status_display.render()

        # ç¶å®šéŸ³è¨Šä¸Šå‚³è™•ç†äº‹ä»¶
        submit_btn.click(
            fn=process_uploaded_audio_fn,
            inputs=[audio_input, chatbot, status_display],
            outputs=[chatbot, status_display, audio_input],
        )

    return demo
