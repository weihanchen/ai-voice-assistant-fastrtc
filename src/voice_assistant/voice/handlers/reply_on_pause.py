"""FastRTC ReplyOnPause è™•ç†å™¨æ•´åˆ

å»ºç«‹ FastRTC èªéŸ³ä¸²æµï¼Œé…ç½® ReplyOnPause æ©Ÿåˆ¶ã€‚
"""

import logging

import gradio as gr
import numpy as np
from fastrtc import AlgoOptions, ReplyOnPause, SileroVadOptions, Stream, WebRTC

from voice_assistant.config import Settings
from voice_assistant.llm.client import LLMClient
from voice_assistant.tools import (
    ExchangeRateTool,
    StockPriceTool,
    ToolRegistry,
    WeatherTool,
)
from voice_assistant.voice.pipeline import VoicePipeline
from voice_assistant.voice.schemas import VoicePipelineConfig
from voice_assistant.voice.ui import (
    additional_outputs_handler,
    audio_input_handler,
    create_additional_outputs,
)

logger = logging.getLogger(__name__)


def create_voice_stream(settings: Settings) -> Stream:
    """å»ºç«‹ FastRTC èªéŸ³ä¸²æµ

    Args:
        settings: æ‡‰ç”¨ç¨‹å¼è¨­å®š

    Returns:
        é…ç½®å¥½çš„ FastRTC Streamï¼ˆå·²è¨­å®šè‡ªå®šç¾© UI èˆ‡äº‹ä»¶ç¶å®šï¼‰
    """
    # åˆå§‹åŒ– LLM Client
    llm_client = LLMClient(
        api_key=settings.openai_api_key,
        model=settings.openai_model,
    )

    # å»ºç«‹èªéŸ³ç®¡ç·šé…ç½®
    config = VoicePipelineConfig(
        stt={
            "model_size": settings.whisper_model_size,
            "model_path": settings.whisper_model_path,
            "language": settings.whisper_language,
            "device": settings.whisper_device,
        },
        tts={
            "model_path": settings.tts_model_path,
            "voice": settings.tts_voice,
            "speed": settings.tts_speed,
        },
        vad={
            "pause_threshold_ms": settings.vad_pause_threshold_ms,
            "min_speech_duration_ms": settings.vad_min_speech_duration_ms,
            "speech_threshold": settings.vad_speech_threshold,
            "min_silence_duration_ms": settings.vad_min_silence_duration_ms,
        },
        can_interrupt=True,
        server_host=settings.server_host,
        server_port=settings.server_port,
    )

    # åˆå§‹åŒ–å·¥å…·è¨»å†Šè¡¨ï¼ˆComposition Rootï¼‰
    tool_registry = ToolRegistry()
    tool_registry.register(WeatherTool())
    tool_registry.register(ExchangeRateTool())
    tool_registry.register(StockPriceTool())

    # åˆå§‹åŒ–èªéŸ³ç®¡ç·š
    pipeline = VoicePipeline(
        config=config,
        llm_client=llm_client,
        tool_registry=tool_registry,
    )

    # å»ºç«‹é¡å¤–è¼¸å‡ºå…ƒä»¶ï¼ˆChatbot å’Œç‹€æ…‹ï¼‰
    chatbot, status_display = create_additional_outputs()

    # å»ºç«‹ FastRTC Streamï¼ˆä½¿ç”¨ process_audio_with_outputs ä»¥æ”¯æ´ AdditionalOutputsï¼‰
    stream = Stream(
        handler=ReplyOnPause(
            pipeline.process_audio_with_outputs,
            algo_options=AlgoOptions(
                audio_chunk_duration=config.vad.pause_threshold_ms / 1000,
                started_talking_threshold=0.2,
                speech_threshold=config.vad.speech_threshold,
            ),
            model_options=SileroVadOptions(
                threshold=0.5,
                min_speech_duration_ms=config.vad.min_speech_duration_ms,
                min_silence_duration_ms=config.vad.pause_threshold_ms,
            ),
            can_interrupt=config.can_interrupt,
            output_sample_rate=config.tts.sample_rate,
        ),
        modality="audio",
        mode="send-receive",
        additional_outputs=[chatbot, status_display],
        additional_outputs_handler=additional_outputs_handler,
    )

    # å»ºç«‹æ¸…é™¤å°è©±çš„å‡½å¼ï¼ˆé–‰åŒ…ï¼Œæ•ç² pipeline åƒè€ƒï¼‰
    def clear_conversation() -> tuple[list[dict[str, str]], str]:
        """æ¸…é™¤å°è©±æ­·å²

        åŒæ™‚æ¸…é™¤ UI é¡¯ç¤ºå’Œ pipeline å…§éƒ¨ç‹€æ…‹ã€‚

        Returns:
            (empty_chatbot, reset_status)
        """
        pipeline.state.history.clear()
        logger.info("[Handler] å°è©±æ­·å²å·²æ¸…é™¤")
        return [], "ğŸŸ¢ å¾…å‘½"

    # å»ºç«‹è™•ç†ä¸Šå‚³éŸ³è¨Šçš„å‡½å¼ï¼ˆé–‰åŒ…ï¼Œæ•ç² pipeline åƒè€ƒï¼‰
    def process_uploaded_audio(
        audio: tuple[int, np.ndarray] | None,
        current_chatbot: list[dict[str, str]],
        current_status: str,
    ) -> tuple[list[dict[str, str]], str, None]:
        """è™•ç†ä¸Šå‚³çš„éŸ³è¨Šæª”æ¡ˆ

        Args:
            audio: (sample_rate, audio_array) æˆ– None
            current_chatbot: ç›®å‰çš„å°è©±è¨˜éŒ„
            current_status: ç›®å‰çš„ç‹€æ…‹æ–‡å­—

        Returns:
            (updated_chatbot, updated_status, cleared_audio_input)
        """
        if audio is None:
            return current_chatbot, current_status, None

        # è½‰æ›éŸ³è¨Šæ ¼å¼
        processed_audio = audio_input_handler(audio)
        if processed_audio is None:
            return current_chatbot, current_status, None

        logger.info("[Handler] é–‹å§‹è™•ç†ä¸Šå‚³çš„éŸ³è¨Šæª”æ¡ˆ")

        # ä½¿ç”¨ pipeline è™•ç†éŸ³è¨Šï¼ˆåŒæ­¥æ–¹å¼ï¼‰
        # æ”¶é›†æ‰€æœ‰è¼¸å‡º
        final_chatbot = current_chatbot
        final_status = current_status

        try:
            for output in pipeline.process_audio_with_outputs(processed_audio):
                # æª¢æŸ¥æ˜¯å¦ç‚º AdditionalOutputs
                if hasattr(output, "args"):
                    # AdditionalOutputs ç‰©ä»¶
                    final_chatbot = output.args[0]
                    final_status = output.args[1]
                # éŸ³è¨Šè¼¸å‡ºåœ¨é€™è£¡å¿½ç•¥ï¼ˆä¸æ’­æ”¾ TTSï¼‰
        except Exception as e:
            logger.error(f"[Handler] è™•ç†ä¸Šå‚³éŸ³è¨Šå¤±æ•—: {e}", exc_info=True)
            final_status = f"âŒ è™•ç†å¤±æ•—: {e}"

        logger.info("[Handler] ä¸Šå‚³éŸ³è¨Šè™•ç†å®Œæˆ")
        return final_chatbot, final_status, None

    # å»ºç«‹è‡ªè¨‚ UIï¼Œæ·»åŠ éŸ³è¨Šä¸Šå‚³åŠŸèƒ½
    sidebar_css = """
    .gradio-container .sidebar {
        background-color: color-mix(
            in srgb, var(--block-background-fill) 50%, transparent
        ) !important;
    }
    body.dark .gradio-container .sidebar {
        background-color: color-mix(
            in srgb, var(--block-background-fill) 50%, transparent
        ) !important;
    }
    """
    with gr.Blocks(title="AI èªéŸ³åŠ©ç†", css=sidebar_css) as custom_ui:
        gr.HTML("<h1 style='text-align: center'>AI èªéŸ³åŠ©ç†</h1>")

        with gr.Row():
            # å·¦å´ï¼šå°è©±è¨˜éŒ„ï¼ˆä¸»è¦å€åŸŸï¼‰
            with gr.Column(scale=2):
                chatbot.render()
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤å°è©±", variant="secondary")

            # å³å´ï¼šæ§åˆ¶å€
            with gr.Column(scale=1):
                # WebRTC ä¸²æµå…ƒä»¶ï¼ˆæ”¾åœ¨å³å´ä¸Šæ–¹ï¼Œé—œé–‰å…¨è¢å¹•æ¨¡å¼ï¼‰
                webrtc = WebRTC(
                    label="èªéŸ³ä¸²æµ",
                    mode="send-receive",
                    modality="audio",
                    full_screen=False,
                )
                stream.webrtc_component = webrtc

                status_display.render()

                # éŸ³è¨Šä¸Šå‚³å€
                with gr.Accordion("ğŸ“ éŸ³è¨Šæª”æ¡ˆæ¸¬è©¦æ¨¡å¼", open=False):
                    gr.Markdown(
                        "ä¸Šå‚³é éŒ„çš„éŸ³è¨Šæª”æ¡ˆä¾†æ¸¬è©¦å°è©±åŠŸèƒ½ï¼Œ"
                        "é©ç”¨æ–¼ç„¡æ³•ä½¿ç”¨éº¥å…‹é¢¨çš„ç’°å¢ƒã€‚"
                    )
                    audio_input = gr.Audio(
                        label="ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ",
                        type="numpy",
                        sources=["upload"],
                    )
                    submit_btn = gr.Button("ğŸ¯ è™•ç†éŸ³è¨Š", variant="primary")

        # ç¶å®š WebRTC ä¸²æµäº‹ä»¶
        webrtc.stream(
            fn=stream.event_handler,
            inputs=[webrtc],
            outputs=[webrtc],
            time_limit=stream.time_limit,
            concurrency_limit=stream.concurrency_limit,
        )

        # ç¶å®š AdditionalOutputs äº‹ä»¶
        webrtc.on_additional_outputs(
            additional_outputs_handler,
            inputs=[chatbot, status_display],
            outputs=[chatbot, status_display],
            concurrency_limit=stream.concurrency_limit,
        )

        # ç¶å®šéŸ³è¨Šä¸Šå‚³è™•ç†äº‹ä»¶
        submit_btn.click(
            fn=process_uploaded_audio,
            inputs=[audio_input, chatbot, status_display],
            outputs=[chatbot, status_display, audio_input],
        )

        # ç¶å®šæ¸…é™¤å°è©±äº‹ä»¶
        clear_btn.click(
            fn=clear_conversation,
            inputs=[],
            outputs=[chatbot, status_display],
        )

    # æ›¿æ› Stream çš„é è¨­ UI
    stream.ui = custom_ui

    return stream
