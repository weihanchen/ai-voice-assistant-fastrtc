"""èªéŸ³ç®¡ç·šä¸»é¡åˆ¥

æ•´åˆ STTã€LLMã€TTS å¯¦ç¾å®Œæ•´èªéŸ³å°è©±æµç¨‹ï¼Œæ”¯æ´è§’è‰²åˆ‡æ›ã€‚
"""

import asyncio
import json
import logging
from collections.abc import Iterator
from typing import TYPE_CHECKING

import numpy as np
from fastrtc import AdditionalOutputs
from numpy.typing import NDArray

from voice_assistant.agents import MultiAgentExecutor
from voice_assistant.config import FlowMode, get_settings
from voice_assistant.flows import FlowExecutor
from voice_assistant.llm.schemas import ChatMessage
from voice_assistant.tools.registry import ToolRegistry
from voice_assistant.voice.schemas import (
    ConversationState,
    VoicePipelineConfig,
    VoiceState,
)
from voice_assistant.voice.stt.whisper import WhisperSTT
from voice_assistant.voice.tts.kokoro import KokoroTTS

# è¨­å®š logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Log æ•æ„Ÿè³‡æ–™æœ€å¤§é•·åº¦ï¼ˆé¿å…æ´©éœ² PIIï¼‰
_LOG_MAX_TEXT_LEN = 50


def _truncate_for_log(text: str, max_len: int = _LOG_MAX_TEXT_LEN) -> str:
    """æˆªæ–·æ–‡å­—ç”¨æ–¼ logï¼Œé¿å…æ•æ„Ÿè³‡æ–™å¤–æ´©"""
    if len(text) <= max_len:
        return text
    return text[:max_len] + "..."


def _run_async_safely(coro):
    """å®‰å…¨åœ°åŸ·è¡Œ async coroutineï¼Œè™•ç† nested event loop æƒ…æ³

    åœ¨ Gradio/FastRTC ç’°å¢ƒä¸­å¯èƒ½å·²æœ‰ event loop åŸ·è¡Œä¸­ï¼Œ
    æ­¤å‡½å¼æœƒåµæ¸¬ä¸¦ä½¿ç”¨é©ç•¶çš„æ–¹å¼åŸ·è¡Œ coroutineã€‚
    """
    try:
        loop = asyncio.get_running_loop()
        # å·²æœ‰åŸ·è¡Œä¸­çš„ loopï¼Œä½¿ç”¨ run_coroutine_threadsafe æ­£ç¢ºæ•´åˆ
        future = asyncio.run_coroutine_threadsafe(coro, loop)
        return future.result()
    except RuntimeError:
        # æ²’æœ‰åŸ·è¡Œä¸­çš„ loopï¼Œç›´æ¥ä½¿ç”¨ asyncio.run()
        return asyncio.run(coro)


if TYPE_CHECKING:
    from voice_assistant.llm.client import LLMClient


class VoicePipeline:
    """èªéŸ³ç®¡ç·šä¸»é¡åˆ¥

    æ•´åˆ STTã€LLMã€TTS å¯¦ç¾å®Œæ•´èªéŸ³å°è©±æµç¨‹ï¼Œæ”¯æ´è§’è‰²åˆ‡æ›ã€‚
    """

    # é è¨­ç³»çµ±æç¤ºè©ï¼ˆç•¶æ²’æœ‰è§’è‰²æ™‚ä½¿ç”¨ï¼‰
    DEFAULT_SYSTEM_PROMPT = (
        "ä½ æ˜¯ä¸€å€‹å‹å–„çš„ AI èªéŸ³åŠ©ç†ã€‚"
        "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œå›ç­”è¦ç°¡æ½”ã€å£èªåŒ–ï¼Œé©åˆèªéŸ³è¼¸å‡ºã€‚"
        "ç•¶ä½¿ç”¨è€…è©¢å•å¤©æ°£ç›¸é—œå•é¡Œæ™‚ï¼Œè«‹ä½¿ç”¨ get_weather å·¥å…·æŸ¥è©¢å¤©æ°£è³‡è¨Šã€‚"
        "ç•¶ä½¿ç”¨è€…è©¢å•åŒ¯ç‡æˆ–è²¨å¹£æ›ç®—ï¼ˆä¾‹å¦‚ï¼šç¾é‡‘åŒ¯ç‡ã€100 ç¾é‡‘æ›å°å¹£ï¼‰æ™‚ï¼Œ"
        "è«‹ä½¿ç”¨ get_exchange_rate å·¥å…·æŸ¥è©¢åŒ¯ç‡æˆ–æ›ç®—çµæœã€‚"
        "ç•¶ä½¿ç”¨è€…è©¢å•è‚¡ç¥¨åƒ¹æ ¼æˆ–è‚¡åƒ¹ï¼ˆä¾‹å¦‚ï¼šå°ç©é›»è‚¡åƒ¹ã€Apple å¤šå°‘éŒ¢ï¼‰æ™‚ï¼Œ"
        "è«‹ä½¿ç”¨ get_stock_price å·¥å…·æŸ¥è©¢è‚¡ç¥¨å ±åƒ¹ã€‚"
        "æ ¹æ“šå·¥å…·å›å‚³çš„è³‡æ–™ï¼Œç”¨è‡ªç„¶çš„å£èªå›æ‡‰ä½¿ç”¨è€…ã€‚"
    )

    def __init__(
        self,
        config: VoicePipelineConfig,
        llm_client: "LLMClient",
        stt: WhisperSTT | None = None,
        tts: KokoroTTS | None = None,
        tool_registry: ToolRegistry | None = None,
        intent_recognizer=None,
        role_registry=None,
        state: ConversationState | None = None,
    ):
        """åˆå§‹åŒ–èªéŸ³ç®¡ç·š

        Args:
            config: ç®¡ç·šé…ç½®
            llm_client: LLM å®¢æˆ¶ç«¯ï¼ˆä¾†è‡ª 000 è¦æ ¼ï¼‰
            stt: STT å¯¦ä¾‹ï¼ˆå¯é¸ï¼Œé è¨­è‡ªå‹•å»ºç«‹ï¼‰
            tts: TTS å¯¦ä¾‹ï¼ˆå¯é¸ï¼Œé è¨­è‡ªå‹•å»ºç«‹ï¼‰
            tool_registry: å·¥å…·è¨»å†Šè¡¨ï¼ˆå¯é¸ï¼Œé è¨­ä½¿ç”¨ç©ºè¨»å†Šè¡¨ï¼‰
            intent_recognizer: æ„åœ–è¾¨è­˜å™¨ï¼ˆ008 è§’è‰²åˆ‡æ›ï¼‰
            role_registry: è§’è‰²è¨»å†Šè¡¨ï¼ˆ008 è§’è‰²åˆ‡æ›ï¼‰
            state: å°è©±ç‹€æ…‹ï¼ˆå¯é¸ï¼Œé è¨­è‡ªå‹•å»ºç«‹ï¼‰
        """
        self.config = config
        self.llm_client = llm_client
        self.state = state if state is not None else ConversationState()

        # 008: è§’è‰²åˆ‡æ›æ”¯æ´
        self.intent_recognizer = intent_recognizer
        self.role_registry = role_registry

        # åˆå§‹åŒ– ToolRegistryï¼ˆç”±å¤–éƒ¨æ³¨å…¥ï¼ŒPipeline ä¸ä¾è³´ç‰¹å®šå·¥å…·ï¼‰
        self.tool_registry = ToolRegistry() if tool_registry is None else tool_registry

        # å–å¾—æµç¨‹æ¨¡å¼è¨­å®š
        settings = get_settings()
        self.flow_mode = settings.flow_mode
        logger.info(f"[Pipeline] æµç¨‹æ¨¡å¼: {self.flow_mode.value}")

        # åˆå§‹åŒ– FlowExecutorï¼ˆLangGraph æµç¨‹ï¼‰
        self.flow_executor: FlowExecutor | None = None
        if self.flow_mode == FlowMode.LANGGRAPH:
            self.flow_executor = FlowExecutor(llm_client, self.tool_registry)
            logger.info("[Pipeline] LangGraph æµç¨‹å·²å•Ÿç”¨")

        # åˆå§‹åŒ– MultiAgentExecutorï¼ˆå¤šä»£ç†å”ä½œï¼‰
        self.multi_agent_executor: MultiAgentExecutor | None = None
        if self.flow_mode == FlowMode.MULTI_AGENT:
            self.multi_agent_executor = MultiAgentExecutor(
                llm_client, self.tool_registry
            )
            logger.info("[Pipeline] Multi-Agent æµç¨‹å·²å•Ÿç”¨")

        # åˆå§‹åŒ– STT
        self.stt = stt or WhisperSTT(
            model_size=config.stt.model_size,
            model_path=config.stt.model_path,
            device=config.stt.device,
            language=config.stt.language,
            beam_size=config.stt.beam_size,
            vad_filter=config.stt.vad_filter,
            min_silence_duration_ms=config.vad.min_silence_duration_ms,
        )

        # åˆå§‹åŒ– TTSï¼ˆmodel_path ç‚º HF_HOME å¿«å–ç›®éŒ„ï¼‰
        self.tts = tts or KokoroTTS(
            model_path=config.tts.model_path,
            voice=config.tts.voice,
            speed=config.tts.speed,
        )

    def switch_role(self, role):
        """åˆ‡æ›ç•¶å‰è§’è‰²

        Args:
            role: è§’è‰²ç‰©ä»¶

        Returns:
            bool: åˆ‡æ›æ˜¯å¦æˆåŠŸ
        """
        if not role or not hasattr(role, "id"):
            return False
        self.state.current_role_id = role.id
        logger.info(
            f"[Pipeline] è§’è‰²å·²åˆ‡æ›ç‚º: "
            f"{role.name if hasattr(role, 'name') else role.id}"
        )
        return True

    def _get_current_system_prompt(self) -> str:
        """å–å¾—ç•¶å‰è§’è‰²çš„ system_prompt

        Returns:
            system_prompt å­—ä¸²
        """
        if self.role_registry and self.state.current_role_id:
            try:
                current_role = self.role_registry.get(self.state.current_role_id)
                logger.debug(
                    f"[Pipeline] ä½¿ç”¨è§’è‰² {current_role.name} çš„ system_prompt"
                )
                return current_role.system_prompt
            except Exception as e:
                logger.warning(f"[Pipeline] ç„¡æ³•å–å¾—ç•¶å‰è§’è‰²çš„ system_prompt: {e}")

        return self.DEFAULT_SYSTEM_PROMPT

    async def _process_tool_calls(
        self,
        messages: list[ChatMessage],
        llm_response: ChatMessage,
        tools: list[dict],
        system_prompt: str | None = None,
    ) -> str:
        """è™•ç† LLM çš„ Tool Calls å›æ‡‰

        Args:
            messages: ç›®å‰çš„å°è©±è¨Šæ¯åˆ—è¡¨
            llm_response: LLM å›æ‡‰ï¼ˆå¯èƒ½åŒ…å« tool_callsï¼‰
            tools: å·¥å…·å®šç¾©åˆ—è¡¨
            system_prompt: ç³»çµ±æç¤ºè©

        Returns:
            æœ€çµ‚çš„æ–‡å­—å›æ‡‰
        """
        # å¦‚æœæ²’æœ‰ tool_callsï¼Œç›´æ¥å›å‚³å…§å®¹
        if not llm_response.tool_calls:
            return llm_response.content or ""

        logger.info(
            f"[Pipeline] LLM è¦æ±‚å‘¼å«å·¥å…·: "
            f"{[tc.function['name'] for tc in llm_response.tool_calls]}"
        )

        # åŠ å…¥ assistant è¨Šæ¯ï¼ˆåŒ…å« tool_callsï¼‰
        messages.append(llm_response)

        # åŸ·è¡Œæ¯å€‹ tool call
        for tool_call in llm_response.tool_calls:
            tool_name = tool_call.function["name"]
            try:
                arguments = json.loads(tool_call.function["arguments"])
            except json.JSONDecodeError as e:
                # JSON è§£æå¤±æ•—æ™‚ï¼Œå›å‚³éŒ¯èª¤è¨Šæ¯çµ¦ LLM
                logger.warning(f"[Pipeline] å·¥å…·åƒæ•¸ JSON è§£æå¤±æ•—: {e}")
                tool_message = ChatMessage(
                    role="tool",
                    content="Error: ç„¡æ³•è§£æå·¥å…·åƒæ•¸",
                    tool_call_id=tool_call.id,
                )
                messages.append(tool_message)
                continue

            logger.info(f"[Pipeline] åŸ·è¡Œå·¥å…· {tool_name}")

            # åŸ·è¡Œå·¥å…·
            result = await self.tool_registry.execute(tool_name, arguments)
            logger.info("[Pipeline] å·¥å…·åŸ·è¡Œå®Œæˆ")

            # åŠ å…¥ tool çµæœè¨Šæ¯
            tool_message = ChatMessage(
                role="tool",
                content=result.to_content(),
                tool_call_id=tool_call.id,
            )
            messages.append(tool_message)

        # å†æ¬¡å‘¼å« LLM ç”¢ç”Ÿæœ€çµ‚å›æ‡‰
        final_response = await self.llm_client.chat(
            messages,
            tools=tools,
            system_prompt=system_prompt or self._get_current_system_prompt(),
        )

        return final_response.content or ""

    async def _process_with_flow(self, user_text: str) -> str:
        """ä½¿ç”¨ LangGraph æµç¨‹è™•ç†ä½¿ç”¨è€…è¼¸å…¥

        Args:
            user_text: ä½¿ç”¨è€…è¼¸å…¥æ–‡å­—

        Returns:
            å›æ‡‰æ–‡å­—
        """
        if self.flow_executor is None:
            raise RuntimeError("FlowExecutor æœªåˆå§‹åŒ–")

        logger.info("[Pipeline] ä½¿ç”¨ LangGraph æµç¨‹è™•ç†")
        return await self.flow_executor.execute(user_text)

    async def _process_with_multi_agent(self, user_text: str) -> str:
        """ä½¿ç”¨ Multi-Agent æµç¨‹è™•ç†ä½¿ç”¨è€…è¼¸å…¥

        Args:
            user_text: ä½¿ç”¨è€…è¼¸å…¥æ–‡å­—

        Returns:
            å›æ‡‰æ–‡å­—
        """
        if self.multi_agent_executor is None:
            raise RuntimeError("MultiAgentExecutor æœªåˆå§‹åŒ–")

        logger.info("[Pipeline] ä½¿ç”¨ Multi-Agent æµç¨‹è™•ç†")
        return await self.multi_agent_executor.execute(user_text)

    async def _process_with_legacy(self, user_text: str) -> str:
        """ä½¿ç”¨èˆŠç‰ˆ Tool Calling è™•ç†ä½¿ç”¨è€…è¼¸å…¥ï¼ˆé™ç´šæ¨¡å¼ï¼‰

        Args:
            user_text: ä½¿ç”¨è€…è¼¸å…¥æ–‡å­—

        Returns:
            å›æ‡‰æ–‡å­—
        """
        logger.info("[Pipeline] ä½¿ç”¨èˆŠç‰ˆ Tool Calling è™•ç†")
        user_message = ChatMessage(role="user", content=user_text)
        messages = [user_message]

        # å–å¾—å·¥å…·å®šç¾©å’Œç•¶å‰ system_prompt
        tools = self.tool_registry.get_openai_tools()
        system_prompt = self._get_current_system_prompt()

        # ç¬¬ä¸€æ¬¡ LLM å‘¼å«
        llm_response = await self.llm_client.chat(
            messages, tools=tools, system_prompt=system_prompt
        )

        # è™•ç† Tool Callsï¼ˆå¦‚æœæœ‰ï¼‰
        return await self._process_tool_calls(
            messages, llm_response, tools, system_prompt
        )

    def process_audio_with_outputs(
        self,
        audio: tuple[int, NDArray[np.float32]],
    ) -> Iterator[tuple[int, NDArray[np.float32]] | AdditionalOutputs]:
        """è™•ç†éŸ³è¨Šè¼¸å…¥ï¼Œå›å‚³èªéŸ³å›æ‡‰ä¸²æµèˆ‡ UI æ›´æ–°

        é€™æ˜¯æ”¯æ´ AdditionalOutputs çš„ FastRTC handlerï¼Œ
        ç”¨æ–¼åŒæ­¥æ›´æ–° Gradio UI å…ƒä»¶ï¼Œä¸¦æ”¯æ´è§’è‰²åˆ‡æ›ã€‚

        Args:
            audio: (sample_rate, audio_array) ä½¿ç”¨è€…èªéŸ³

        Yields:
            - AdditionalOutputs(history, status): UI æ›´æ–°
            - (sample_rate, audio_chunk): åŠ©ç†èªéŸ³å›æ‡‰
        """
        # æ›´æ–°ç‹€æ…‹ç‚ºè™•ç†ä¸­
        self.state.transition_to(VoiceState.PROCESSING)
        sample_rate, audio_array = audio
        logger.info(
            f"[Pipeline] æ”¶åˆ°éŸ³è¨Š: sample_rate={sample_rate}, "
            f"shape={audio_array.shape}, dtype={audio_array.dtype}"
        )

        # ç™¼é€åˆå§‹ç‹€æ…‹æ›´æ–°
        yield AdditionalOutputs(
            self.state.get_gradio_messages(),
            self.state.get_ui_state().status_text,
        )

        try:
            # 1. èªéŸ³è½‰æ–‡å­—
            logger.info("[Pipeline] é–‹å§‹ STT è¾¨è­˜...")
            user_text = self.stt.stt(audio)
            logger.debug(f"[Pipeline] STT çµæœ: '{_truncate_for_log(user_text)}'")

            if not user_text.strip():
                # ç„¡æœ‰æ•ˆè¼¸å…¥ï¼Œå›åˆ°å¾…å‘½
                logger.info("[Pipeline] ç„¡æœ‰æ•ˆèªéŸ³è¼¸å…¥ï¼Œè·³é")
                self.state.transition_to(VoiceState.IDLE)
                yield AdditionalOutputs(
                    self.state.get_gradio_messages(),
                    self.state.get_ui_state().status_text,
                )
                return

            # --------- 008: INTENT è¾¨è­˜ï¼ˆè§’è‰²åˆ‡æ›ï¼‰ ---------
            if self.intent_recognizer is not None and self.role_registry is not None:
                try:
                    intent = _run_async_safely(
                        self.intent_recognizer.recognize_intent_with_llm(user_text)
                    )
                except Exception as e:
                    logger.error(f"[Pipeline] è¾¨è­˜æ„åœ–å¤±æ•—ï¼š{e}")
                    intent = None

                logger.debug(
                    f"[Intent] è¼¸å…¥: user_text='{_truncate_for_log(user_text)}' "
                    f"intent={getattr(intent, 'name', None)} "
                    f"params={getattr(intent, 'params', None)}"
                )

                if (
                    intent is not None
                    and getattr(intent, "name", None) == "switch_role"
                    and hasattr(intent, "params")
                ):
                    logger.info("[Pipeline] åµæ¸¬åˆ°è§’è‰²åˆ‡æ›æŒ‡ä»¤")
                    role_id = intent.params.get("role_id")

                    # å…è¨±ç”¨ display_nameï¼ˆå¦‚ã€ŒåŠ©ç†ã€ï¼‰è‡ªå‹•æ˜ å°„ ID
                    if role_id and role_id not in self.role_registry._roles:
                        mapped_id = self.role_registry.get_id_by_name(role_id)
                        if mapped_id:
                            logger.info(
                                f"[Pipeline] nameâ†’ID æ˜ å°„: {role_id} -> {mapped_id}"
                            )
                            role_id = mapped_id

                    role = self.role_registry.get(role_id) if role_id else None

                    if role:
                        logger.info(
                            f"[Pipeline] åˆ‡æ›åˆ°è§’è‰²: {getattr(role, 'name', role_id)}"
                        )
                        result = self.switch_role(role)

                        if result:
                            # å…ˆå˜—è©¦æŠ“è§’è‰²çš„æ­¡è¿è©ï¼Œæœ‰å‰‡å„ªå…ˆç”¨ï¼›æ²’æœ‰æ‰ fallback
                            welcome_txt = (
                                role.get_welcome_message()
                                if hasattr(role, "get_welcome_message")
                                else None
                            )
                            if welcome_txt:
                                # TTS æ’­æ”¾åŸå§‹æ­¡è¿èªï¼ˆç„¡åˆ†éš”ç¬¦ï¼‰
                                tts_txt = welcome_txt
                                # å°è©±æ¡†é¡¯ç¤ºæ™‚åŠ å…¥è¦–è¦ºåˆ†éš”ï¼Œæå‡è¾¨è­˜åº¦
                                display_txt = f"---\n\n{welcome_txt}"
                                role_name = getattr(role, "name", "æœªçŸ¥è§’è‰²")
                                status_txt = f"ğŸŸ¢ å·²åˆ‡æ›ç‚ºã€{role_name}ã€æ¨¡å¼"
                            else:
                                role_name = getattr(role, "name", "æœªçŸ¥è§’è‰²")
                                tts_txt = f"å·²åˆ‡æ›ç‚ºã€{role_name}ã€æ¨¡å¼, è«‹ç¹¼çºŒæå•"
                                display_txt = (
                                    f"---\n\nå·²åˆ‡æ›ç‚ºã€{role_name}ã€æ¨¡å¼, è«‹ç¹¼çºŒæå•"
                                )
                                status_txt = f"ğŸŸ¢ å·²åˆ‡æ›ç‚ºã€{role_name}ã€æ¨¡å¼"
                        else:
                            tts_txt = (
                                self.state.last_assistant_text
                                or "è§’è‰²è¨­å®šç•°å¸¸ï¼Œè«‹ç¢ºèªå¾Œå†è©¦ä¸€æ¬¡ã€‚"
                            )
                            display_txt = tts_txt
                            status_txt = f"âš ï¸ {tts_txt}"
                    else:
                        tts_txt = "æŸ¥ç„¡æ­¤è§’è‰²ï¼Œè«‹å†èªªä¸€æ¬¡æˆ–å¾é¸å–®åˆ‡æ›ã€‚"
                        display_txt = tts_txt
                        status_txt = f"âš ï¸ {tts_txt}"

                    # æ’­æ”¾ TTS ç¢ºèªè¨Šæ¯ï¼ˆä½¿ç”¨ç„¡åˆ†éš”ç¬¦ç‰ˆæœ¬ï¼‰
                    for audio_chunk in self.tts.stream_tts_sync(tts_txt):
                        yield audio_chunk

                    self.state.last_assistant_text = display_txt
                    self.state.history.add_assistant_message(display_txt)
                    self.state.transition_to(VoiceState.IDLE)
                    yield AdditionalOutputs(
                        self.state.get_gradio_messages(), status_txt
                    )
                    logger.debug("[Pipeline] è§’è‰²åˆ‡æ›å®Œæˆï¼ŒçµæŸè™•ç†")
                    return

                # ä¸æ˜¯ switch_role intent æ™‚ï¼Œé€²å…¥ä¸»æµç¨‹è™•ç†
                logger.info("[Pipeline] é€²å…¥ä¸€èˆ¬å°è©±æµç¨‹")

            # T013: STT å®Œæˆå¾Œæ›´æ–° history
            self.state.last_user_text = user_text
            self.state.history.add_user_message(user_text)
            self.state.transition_to(VoiceState.PROCESSING)

            # ç™¼é€ UI æ›´æ–°ï¼šä½¿ç”¨è€…è¨Šæ¯å·²åŠ å…¥
            yield AdditionalOutputs(
                self.state.get_gradio_messages(),
                self.state.get_ui_state().status_text,
            )

            # 2. æ ¹æ“š flow_mode è™•ç†è¼¸å…¥
            logger.debug(f"[Pipeline] è™•ç†è¼¸å…¥: '{_truncate_for_log(user_text)}'")

            # æ±ºå®šæœ‰æ•ˆçš„æµç¨‹æ¨¡å¼ï¼ˆè§’è‰²å°ˆå±¬ > å…¨åŸŸè¨­å®šï¼‰
            effective_flow_mode = self.flow_mode  # é è¨­ä½¿ç”¨å…¨åŸŸè¨­å®š
            if self.role_registry and self.state.current_role_id:
                current_role = self.role_registry.get(self.state.current_role_id)
                if (
                    current_role
                    and hasattr(current_role, "preferred_flow_mode")
                    and current_role.preferred_flow_mode
                ):
                    effective_flow_mode = FlowMode(current_role.preferred_flow_mode)
                    logger.info(
                        f"[Pipeline] ä½¿ç”¨è§’è‰²å°ˆå±¬æµç¨‹æ¨¡å¼: {effective_flow_mode.value}"
                    )
                else:
                    logger.info(
                        f"[Pipeline] ä½¿ç”¨å…¨åŸŸæµç¨‹æ¨¡å¼: {effective_flow_mode.value}"
                    )
            else:
                logger.info(f"[Pipeline] ä½¿ç”¨å…¨åŸŸæµç¨‹æ¨¡å¼: {effective_flow_mode.value}")

            if effective_flow_mode == FlowMode.MULTI_AGENT:
                # ä½¿ç”¨ Multi-Agent æµç¨‹
                response = _run_async_safely(self._process_with_multi_agent(user_text))
            elif effective_flow_mode == FlowMode.LANGGRAPH:
                # ä½¿ç”¨ LangGraph æµç¨‹
                response = _run_async_safely(self._process_with_flow(user_text))
            else:
                # FlowMode.TOOLS - ä½¿ç”¨ç´” Tool Calling
                response = _run_async_safely(self._process_with_legacy(user_text))

            logger.debug(f"[Pipeline] å›æ‡‰: '{_truncate_for_log(response)}'")

            # T014: LLM å›æ‡‰å¾Œæ›´æ–° history
            self.state.last_assistant_text = response
            self.state.history.add_assistant_message(response)

            # 3. æ›´æ–°ç‹€æ…‹ç‚ºå›æ‡‰ä¸­
            self.state.transition_to(VoiceState.SPEAKING)
            self.state.turn_count += 1

            # ç™¼é€ UI æ›´æ–°ï¼šåŠ©ç†å›æ‡‰å·²åŠ å…¥
            yield AdditionalOutputs(
                self.state.get_gradio_messages(),
                self.state.get_ui_state().status_text,
            )

            # 4. TTS ä¸²æµè¼¸å‡º
            logger.info("[Pipeline] é–‹å§‹ TTS ä¸²æµ...")
            chunk_count = 0
            interrupted = False
            for audio_chunk in self.tts.stream_tts_sync(response):
                # æª¢æŸ¥æ˜¯å¦è¢«ä¸­æ–·ï¼ˆåƒ…ç•¶ can_interrupt å•Ÿç”¨æ™‚ï¼‰
                if (
                    self.config.can_interrupt
                    and self.state.state == VoiceState.INTERRUPTED
                ):
                    logger.info("[Pipeline] TTS è¢«ä¸­æ–·ï¼Œåœæ­¢è¼¸å‡º")
                    interrupted = True
                    break
                chunk_count += 1
                yield audio_chunk

            if interrupted:
                logger.info(f"[Pipeline] TTS ä¸­æ–·æ–¼ç¬¬ {chunk_count} å€‹éŸ³è¨Šç‰‡æ®µ")
                yield AdditionalOutputs(
                    self.state.get_gradio_messages(),
                    "â¸ï¸ å·²ä¸­æ–·",
                )
            else:
                logger.info(f"[Pipeline] TTS å®Œæˆï¼Œå…± {chunk_count} å€‹éŸ³è¨Šç‰‡æ®µ")

            # 5. å›æ‡‰å®Œæˆï¼Œå›åˆ°å¾…å‘½
            self.state.transition_to(VoiceState.IDLE)
            yield AdditionalOutputs(
                self.state.get_gradio_messages(),
                self.state.get_ui_state().status_text,
            )

        except Exception as e:
            # éŒ¯èª¤è™•ç†ï¼šæ’­æ”¾éŒ¯èª¤æç¤º
            logger.error(f"[Pipeline] è™•ç†éŒ¯èª¤: {e}", exc_info=True)
            error_message = "æŠ±æ­‰ï¼Œè™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚"

            # ç™¼é€éŒ¯èª¤ç‹€æ…‹
            yield AdditionalOutputs(
                self.state.get_gradio_messages(),
                "âŒ ç™¼ç”ŸéŒ¯èª¤",
            )

            try:
                for audio_chunk in self.tts.stream_tts_sync(error_message):
                    yield audio_chunk
            except Exception as tts_error:
                logger.error(f"[Pipeline] éŒ¯èª¤è¨Šæ¯ TTS å¤±æ•—: {tts_error}")
            finally:
                self.state.transition_to(VoiceState.IDLE)
                yield AdditionalOutputs(
                    self.state.get_gradio_messages(),
                    self.state.get_ui_state().status_text,
                )

    def on_interrupt(self) -> None:
        """è™•ç†ä½¿ç”¨è€…ä¸­æ–·

        ç•¶ä½¿ç”¨è€…åœ¨åŠ©ç†å›æ‡‰æ™‚é–‹å§‹èªªè©±ï¼Œç”± FastRTC å‘¼å«ã€‚
        """
        if self.state.state == VoiceState.SPEAKING:
            self.state.transition_to(VoiceState.INTERRUPTED)
            # FastRTC æœƒè‡ªå‹•åœæ­¢æ’­æ”¾

    def get_state(self) -> ConversationState:
        """å–å¾—ç›®å‰å°è©±ç‹€æ…‹"""
        return self.state

    def reset(self) -> None:
        """é‡ç½®å°è©±ç‹€æ…‹"""
        self.state = ConversationState()
