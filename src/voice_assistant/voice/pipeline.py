import logging
from collections.abc import Iterator

from fastrtc import AdditionalOutputs
from numpy.typing import NDArray

from voice_assistant.voice.schemas import VoiceState

logger = logging.getLogger(__name__)


class VoicePipeline:
    def __init__(
        self,
        state,
        stt,
        tts,
        intent_recognizer=None,
        role_registry=None,
        config=None,
        llm_client=None,
        tool_registry=None,
    ):
        self.state = state
        self.stt = stt
        self.tts = tts
        self.intent_recognizer = intent_recognizer
        self.role_registry = role_registry
        self.config = config
        self.llm_client = llm_client
        self.tool_registry = tool_registry

    def switch_role(self, role):
        if not role or not hasattr(role, "id"):
            return False
        self.state.current_role_id = role.id
        return True

    def process_audio_with_outputs(
        self, audio: tuple[int, NDArray]
    ) -> Iterator[tuple[int, NDArray] | AdditionalOutputs]:
        self.state.transition_to(VoiceState.PROCESSING)
        sample_rate, audio_array = audio
        logger.info(
            f"[Pipeline] æ”¶åˆ°éŸ³è¨Š: sample_rate={sample_rate}, "
            f"shape={audio_array.shape}, dtype={audio_array.dtype}"
        )
        # ç™¼é€åˆå§‹ç‹€æ…‹æ›´æ–°
        yield AdditionalOutputs(
            self.state.get_gradio_messages(),
            self.state.get_ui_state().status_text,
        )
        try:
            # 1. èªéŸ³è½‰æ–‡å­—
            logger.info("[Pipeline] é–‹å§‹ STT è¾¨è­˜...")
            user_text = self.stt.stt(audio)
            logger.debug(f"[Pipeline] STT çµæœ: '{user_text}'")
            if not user_text.strip():
                # ç„¡æœ‰æ•ˆèªéŸ³è¼¸å…¥ï¼Œå›åˆ°å¾…å‘½
                logger.info("[Pipeline] ç„¡æœ‰æ•ˆèªéŸ³è¼¸å…¥ï¼Œè·³é")
                self.state.transition_to(VoiceState.IDLE)
                yield AdditionalOutputs(
                    self.state.get_gradio_messages(),
                    self.state.get_ui_state().status_text,
                )
                logger.debug("[Pipeline] generator exit: no valid STT input")
                return
            # --------- INTENT è¾¨è­˜ï¼ˆå¦‚æ”¯æ´ï¼‰ ---------
            if self.intent_recognizer is not None and self.role_registry is not None:
                import asyncio

                try:
                    intent = asyncio.run(
                        self.intent_recognizer.recognize_intent_with_llm(user_text)
                    )
                except Exception as e:
                    logger.error(f"[Pipeline] è¾¨è­˜æ„åœ–å¤±æ•—ï¼š{e}")
                    intent = None
                logger.critical(
                    f"[IntentåµéŒ¯] è¼¸å…¥: user_text='{user_text}' "
                    f"intent={getattr(intent, 'name', None)} "
                    f"params={getattr(intent, 'params', None)}"
                )
                if (
                    intent is not None
                    and getattr(intent, "name", None) == "switch_role"
                    and hasattr(intent, "params")
                ):
                    logger.info("[Pipeline] Triggering role switch branch...")
                    role_id = intent.params.get("role_id")
                    # æ–°å¢ï¼šå…è¨±ç”¨ display_nameï¼ˆå¦‚ã€ŒåŠ©ç†ã€ï¼‰è‡ªå‹•æ˜ å°„ ID
                    if role_id and role_id not in self.role_registry._roles:
                        mapped_id = self.role_registry.get_id_by_name(role_id)
                        if mapped_id:
                            logger.info(
                                f"[Pipeline] nameâ†’ID æ˜ å°„: {role_id} -> {mapped_id}"
                            )
                            role_id = mapped_id
                    role = self.role_registry.get(role_id) if role_id else None
                    if role:
                        logger.info(
                            f"[Pipeline] Switching to role: "
                            f"{getattr(role, 'name', role_id)}"
                        )
                        result = self.switch_role(role)
                        if result:
                            role_name = getattr(role, "name", "æœªçŸ¥è§’è‰²")
                            reply_txt = f"å·²åˆ‡æ›ç‚ºã€{role_name}ã€æ¨¡å¼, è«‹ç¹¼çºŒæå•"
                            status_txt = f"ğŸŸ¢ {reply_txt}"
                        else:
                            reply_txt = (
                                self.state.last_assistant_text
                                or "è§’è‰²è¨­å®šç•°å¸¸ï¼Œè«‹ç¢ºèªå¾Œå†è©¦ä¸€æ¬¡ã€‚"
                            )
                            status_txt = f"âš ï¸ {reply_txt}"
                    else:
                        reply_txt = "æŸ¥ç„¡æ­¤è§’è‰²ï¼Œè«‹å†èªªä¸€æ¬¡æˆ–å¾é¸å–®åˆ‡æ›ã€‚"
                        status_txt = f"âš ï¸ {reply_txt}"
                    for audio_chunk in self.tts.stream_tts_sync(reply_txt):
                        yield audio_chunk
                    self.state.last_assistant_text = reply_txt
                    self.state.history.add_assistant_message(reply_txt)
                    self.state.transition_to(VoiceState.IDLE)
                    yield AdditionalOutputs(
                        self.state.get_gradio_messages(), status_txt
                    )
                    logger.debug(
                        "[Pipeline] generator exit: role switch intent handled"
                    )
                    return
                # ä¸æ˜¯ switch_role intent æ™‚ï¼Œé€²å…¥ä¸»æµç¨‹è™•ç†
                logger.info("[Pipeline] Normal conversation branch.")

            # T013: STT å®Œæˆå¾Œæ›´æ–° history
            self.state.last_user_text = user_text
            self.state.history.add_user_message(user_text)
            self.state.transition_to(VoiceState.PROCESSING)
            # ç™¼é€ UI æ›´æ–°ï¼šä½¿ç”¨è€…è¨Šæ¯å·²åŠ å…¥
            yield AdditionalOutputs(
                self.state.get_gradio_messages(),
                self.state.get_ui_state().status_text,
            )
            # 2. æ ¹æ“š flow_mode è™•ç†è¼¸å…¥
            logger.debug(f"[Pipeline] è™•ç†è¼¸å…¥: '{user_text}'")
            import asyncio

            from voice_assistant.llm.schemas import ChatMessage

            if self.llm_client:
                messages = [ChatMessage(role="user", content=user_text)]

                # å–å¾—ç•¶å‰è§’è‰²çš„ system_prompt
                current_system_prompt = None
                if self.role_registry and self.state.current_role_id:
                    try:
                        current_role = self.role_registry.get(
                            self.state.current_role_id
                        )
                        current_system_prompt = current_role.system_prompt
                        logger.debug(
                            f"[Pipeline] ä½¿ç”¨è§’è‰² {current_role.name} çš„ system_prompt"
                        )
                    except Exception as e:
                        logger.warning(
                            f"[Pipeline] ç„¡æ³•å–å¾—ç•¶å‰è§’è‰²çš„ system_prompt: {e}"
                        )

                try:
                    response_msg = asyncio.run(
                        self.llm_client.chat(
                            messages,
                            tools=self.tool_registry.get_openai_tools()
                            if self.tool_registry
                            else None,
                            system_prompt=current_system_prompt,
                        )
                    )
                    response = response_msg.content or ""
                except Exception as e:
                    logger.error(f"LLM å›æ‡‰å¤±æ•—: {e}")
                    response = "ï¼ˆç³»çµ±ï¼‰èªè¨€æ¨¡å‹å›æ‡‰å¤±æ•—ã€‚"
            else:
                response = "ï¼ˆç³»çµ±ï¼‰æœªè¨­å®š LLM Clientï¼Œç„¡æ³•å›æ‡‰ã€‚"

            # é˜²ç¦¦æ€§æª¢æŸ¥ï¼šç¢ºä¿å›æ‡‰ä¸ç‚ºç©º
            if not response or not response.strip():
                logger.warning("[Pipeline] LLM å›æ‡‰ç‚ºç©ºï¼Œä½¿ç”¨é è¨­è¨Šæ¯")
                response = "æŠ±æ­‰ï¼Œæˆ‘æš«æ™‚ç„¡æ³•å›æ‡‰ã€‚è«‹å†èªªä¸€æ¬¡ã€‚"

            logger.debug(f"[Pipeline] å›æ‡‰: '{response}'")
            # T014: LLM å›æ‡‰å¾Œæ›´æ–° history
            self.state.last_assistant_text = response
            self.state.history.add_assistant_message(response)
            # 3. æ›´æ–°ç‹€æ…‹ç‚ºå›æ‡‰ä¸­
            self.state.transition_to(VoiceState.SPEAKING)
            self.state.turn_count += 1
            # ç™¼é€ UI æ›´æ–°ï¼šåŠ©ç†å›æ‡‰å·²åŠ å…¥
            yield AdditionalOutputs(
                self.state.get_gradio_messages(),
                self.state.get_ui_state().status_text,
            )
            # 4. TTS ä¸²æµè¼¸å‡º
            logger.info("[Pipeline] é–‹å§‹ TTS ä¸²æµ...")
            chunk_count = 0
            interrupted = False
            for audio_chunk in self.tts.stream_tts_sync(response):
                # æª¢æŸ¥æ˜¯å¦è¢«ä¸­æ–·ï¼ˆåƒ…ç•¶ can_interrupt å•Ÿç”¨æ™‚ï¼‰
                if (
                    self.config
                    and self.config.can_interrupt
                    and self.state.state == VoiceState.INTERRUPTED
                ):
                    logger.info("[Pipeline] TTS è¢«ä¸­æ–·ï¼Œåœæ­¢è¼¸å‡º")
                    interrupted = True
                    break
                chunk_count += 1
                yield audio_chunk
            if interrupted:
                logger.info(f"[Pipeline] TTS ä¸­æ–·æ–¼ç¬¬ {chunk_count} å€‹éŸ³è¨Šç‰‡æ®µ")
                yield AdditionalOutputs(
                    self.state.get_gradio_messages(),
                    "â¸ï¸ å·²ä¸­æ–·",
                )
                return
            else:
                logger.info(f"[Pipeline] TTS å®Œæˆï¼Œå…± {chunk_count} å€‹éŸ³è¨Šç‰‡æ®µ")
            # 5. å›æ‡‰å®Œæˆï¼Œå›åˆ°å¾…å‘½
            self.state.transition_to(VoiceState.IDLE)
            yield AdditionalOutputs(
                self.state.get_gradio_messages(),
                self.state.get_ui_state().status_text,
            )
            return
        except Exception as e:
            # éŒ¯èª¤è™•ç†ï¼šæ’­æ”¾éŒ¯èª¤æç¤º
            logger.error(f"[Pipeline] è™•ç†éŒ¯èª¤: {e}", exc_info=True)
            error_message = "æŠ±æ­‰ï¼Œè™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚"
            # ç™¼é€éŒ¯èª¤ç‹€æ…‹
            yield AdditionalOutputs(
                self.state.get_gradio_messages(),
                "âŒ ç™¼ç”ŸéŒ¯èª¤",
            )
            try:
                for audio_chunk in self.tts.stream_tts_sync(error_message):
                    yield audio_chunk
            except Exception as tts_error:
                logger.error(f"[Pipeline] éŒ¯èª¤è¨Šæ¯ TTS å¤±æ•—: {tts_error}")
            finally:
                self.state.transition_to(VoiceState.IDLE)
                yield AdditionalOutputs(
                    self.state.get_gradio_messages(),
                    self.state.get_ui_state().status_text,
                )
                return
